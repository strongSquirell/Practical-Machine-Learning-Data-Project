---
title: "Practical Machine Learning. Course Project"
author: "Alina Rusina"
date: "March 31, 2016"
output: html_document
---

In this project we use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har
We built model to predict the manner in which they did the exercise.
First of all, lets take a look at the data set

```{r}
trainingURL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testURL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(trainingURL, na.strings = c("NA", ""))
testing <- read.csv(testURL, na.strings = c("NA", ""))
str(training)
```

We remove unuseful columns and columns which mostly equals NA.
```{r}
training1 <- training[, 7:160]
testing1 <- testing[, 7:160]

removingNA <- apply(!is.na(training1), 2, sum) > 19621
training2 <- training1[, removingNA]
testing2 <- testing1[, removingNA]
dim(training2)
```

We reduce number of columns from 165 to 54.
Since my laptop can not handle this huge amount of data, I subset it
```{r, warning = FALSE}
library(caret)
inTrain <- createDataPartition(y = training2$classe, p = 0.2, list = FALSE)
training3 <- training2[inTrain,]
```

Now, we create data partitioning on training data set:
```{r}
inTrain <- createDataPartition(y = training3$classe, p = 0.7, list = FALSE)
training4 <- training3[inTrain,]
testing4 <- training3[-inTrain,]
```

Next, we train our model using random forest method (as the most accurate classification method)
```{r, warning = FALSE}
library(randomForest)
modFit <- train(classe ~ ., data = training4, method = "rf",
                trControl = trainControl(method = "cv", number = 4),
                prox = TRUE, allowParallel = TRUE)
modFit
modFit$finalModel
```
We use cross validation to choose best set of parameters.
Now, we use our model to predict some value. Since, we do not use data from testing4, 
error in this prediction will be close to out of sample error.
```{r}
pred <- predict(modFit, testing4)
testing4$predRight <- pred==testing4$classe
table(pred, testing4$classe)
```

As we can see, error is around 2%.